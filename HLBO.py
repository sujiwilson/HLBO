# -*- coding: utf-8 -*-
"""HLBO_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-T7UpAQ6fmhuBRKomOEaVhTTS1xehKSt
"""

import time
import numpy as np
rng = np.random.default_rng()
from numpy import random
import math
from numpy import inf
from numpy.random import rand

#Calculate fitness values for each member
def fun(X):
    output = sum(np.square(X))
    return output

def get_minvalue(a):
 
    min_val = a.min() 
 
    min_idxs = [idx for idx, val in enumerate(a) if val == min_val] 
    #return the index of Min.Val 

    min_idxs=min_idxs[0]
    return min_val,min_idxs

def get_maxvalue(a):
 
    max_val = a.max()
 
    max_idxs = [idx for idx, val in enumerate(a) if val == max_val] 
    max_idxs=max_idxs[0]
    #return the index of Max.Val

    return max_val,max_idxs

# function  to initialize the  population.
def init_position(lb, ub, N, dim):
    X = np.zeros([N, dim], dtype='float')
    for i in range(N):
        for d in range(dim):
            X[i,d] = lb[0,d] + (ub[0,d] - lb[0,d]) * rand()        
    
    return X

def HLBO(SearchAgents,dimension,Max_iterations,lowerbound,upperbound,fun):
  fit    = np.zeros([SearchAgents, 1], dtype='float')
  Q = np.zeros([1, dim], dtype='float')
  best_so_far = np.zeros([Max_iterations, 1])

  X      = init_position(lowerbound, upperbound, SearchAgents, dimension)        
  
  HL = np.zeros(X.shape)
  Xk = np.zeros(X.shape)
  print(Xk.shape)
  for i in range(SearchAgents):
    fit[i,0]=fun(X[i,:])
  for t in range(Max_iterations):
    #update the best member
    [best , blocation]=get_minvalue(fit);
    [fworst , wlocation]=get_maxvalue(fit);
    # Phase 1: Exploration phase
    # candidate solution
    for i in range(SearchAgents):
      Q=fit-fworst/fit[i,0]-fworst             #eqn(4)
  
    if t==0:
        Xbest=X[blocation,:]                                          # Optimal location
        Qbest=Q[blocation,:]
        fbest=best                                               #The optimization objective function
        
    elif best<fbest: 
        fbest=best
        Xbest=X[blocation,:]
        Qbest=Q[blocation,:]
    k=np.random.permutation(SearchAgents)
    PCi=Q[i]/Q[i]+Qbest+Q[k[i]]             #eqn 5.
    PCbest=Qbest/Q[i]+Qbest+Q[k[i]]
    PCk=Q[k[i]]/Q[i]+Qbest+Q[k[i]]
    Xk[i,:]=X[k[i],:]
    for j in range(dimension):   
      HL[i,j]=np.multiply(PCi,X[i,j])+np.multiply(PCbest,Xbest[j])+np.multiply(PCk,Xk[i,j])    #eqn.6

    XF=np.column_stack((X,fit))
    XFsort=np.sort(XF)
    X=XFsort[:,0:dimension]
    fit=XFsort[:,-1:]
    XFsort=fit
    F_DI=XFsort
    # update HLBO population      
      # Phase 1: Exploration (global search)
    k_i=np.random.permutation(SearchAgents)
    F_HL_ki=F_DI[k_i[0]]
    I=np.round(1+random.rand(1,1))
    if F_HL_ki< fit [i,0]:
        X_P1=X[i,:]+np.multiply(random.rand(1,1),(HL[i,:]-np.multiply(I,X[i,:])))             # Eq. (7)
    else:
        X_P1=X[i,:]+np.multiply(random.rand(1,1), (np.multiply(1,X[i,:])-HL[i,:]))
     
      # Update X_i based on Eq(8)
    F_P1= fun(X_P1[0,:])

    if F_P1 <= fit [i,0]:
        X[i,:] = X_P1
        fit [i,0]=F_P1

      #END Phase 1:  (exploration)

      #Phase 2: Exploitation (local search)
    R=0.05;
    X_P2= X[i,:]+ (1-2*rand(1,dimension))*R*np.multiply((1-t/Max_iterations),X[i,:])      #Eq.(9)
      #Update X_i based on Eq(10)
    F_P2 = fun(X_P2[0,:]);
    if F_P2 <= fit [i,0]:
        X[i,:] = X_P2
        fit [i,0]=F_P2

      #END Phase of exploitation
        
    best_so_far[t]=fbest
    
# END for t=1:Max_iterations
  Best_score=fbest
  Best_pos=Xbest
  DTBO_curve=best_so_far

  return Best_score,Best_pos,DTBO_curve,best_so_far

time_start = time.time()
pop = 10                    #  population size.
MaxIter = 300               # Maximum number of iterations.
dim = 5                    # The dimension.
lb=-1                     # The lower bound of the search interval.
ub=1                     # The upper bound of the search interval.
ub = ub * np.ones([1, dim], dtype='float')
lb = lb * np.ones([1, dim], dtype='float')
GbestScore, GbestPositon, Curve,best_so_far = HLBO(pop, dim, MaxIter, lb, ub, fun)
time_end = time.time()
print(f"The running time is: {time_end  - time_start } s")
print('The optimal value：',GbestScore)
print('The optimal solution：',GbestPositon)

import matplotlib.pyplot as plt
fig, ax = plt.subplots()
ax.plot( Curve,color='b', marker='o', markeredgecolor='b', markerfacecolor='b')
ax.set_xlabel('Number of Iterations',fontsize=15)
ax.set_ylabel('Fitness',fontsize=15)
ax.set_title('HLBO')
plt.savefig('image.jpg', format='jpg')
plt.show()
